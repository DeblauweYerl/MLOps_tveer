{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","import os\n","from glob import glob\n","import numpy as np\n","from typing import List"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.insert(0, \"./ai\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from AI import *"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["processed_components_folder = 'assets/media/processed_components'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["components_in_pack = ['Object 1', 'Object 3'] # The components you want to train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_components = []\n","all_labels = []\n","all_sizes = []\n","for comp in components_in_pack:\n","    for img_uri in glob(os.path.join(processed_components_folder, comp) + \"/*.png\"):\n","        try:\n","            size = img_uri.split(\".png\")[-2]\n","            with open(size + '--size.json', \"r\") as f:\n","                all_sizes.append(json.load(f))\n","                img = imread(img_uri)[:,:,:3] / 255\n","                all_components.append(img)\n","                all_labels.append(comp)\n","        except FileNotFoundError:\n","            pass\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","all_labels_np = np.array(all_labels)\n","all_components_np = np.array(all_components)\n","all_sizes_np = np.array(all_sizes)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","print(all_labels_np.shape)\n","print(all_components_np.shape)\n","print(all_sizes_np.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(all_labels_np)\n","\n","# binary encode\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","\n","import math\n","\n","training_indices = []\n","test_indices = []\n","for obj in range(0, onehot_encoded.shape[1]):\n","    obj_indices = np.where(onehot_encoded[:,obj] == 1)[0]\n","    np.random.shuffle(obj_indices)\n","    training_samples = math.floor(0.7 * len(obj_indices))\n","    training_indices.extend(obj_indices[:training_samples])\n","    test_indices.extend(obj_indices[training_samples:])\n","\n","print(f\"{len(training_indices)} training indices\")\n","print(f\"{len(test_indices)} test indices\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","X_train_conv = all_components_np[training_indices]\n","X_train_values = all_sizes_np[training_indices]\n","X_test_conv = all_components_np[test_indices]\n","X_test_values = all_sizes_np[test_indices]\n","\n","y_train = onehot_encoded[training_indices]\n","y_test = onehot_encoded[test_indices]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","import tensorflow as tf\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","import tensorflow.keras\n","from tensorflow.keras.layers import Flatten, Input, concatenate, Dense, Activation, Dropout, BatchNormalization,  MaxPooling2D, AveragePooling2D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# CNN - VGG\n","X_conv = Input(shape=(64, 64, 3))\n","\n","vgg_model = VGG19(include_top=False, weights='imagenet')(X_conv)    # Add all the layers of the VGG19 model\n","# vgg_model.trainable = False\n","# vgg_model[-1].trainable = True\n","## Eventueel naar voor terugschuiven om op false te zetten\n","\n","x_1 = Flatten(name='flatten')(vgg_model)\n","x_1 = Dense(512, activation='relu', name='fully-connected-1')(x_1)\n","x_1 = Dense(128, activation='relu', name='fully-connected-2')(x_1)\n","x_1 = Dense(16, activation='relu', name='fully-connected-3')(x_1)\n","\n","# x_1 = Dense(6, activation='relu', name='fully-connected-TEST')(x_1)\n","# final_model = Model(inputs=X_conv, outputs=x_1)\n","\n","X_extra = Input(shape=(1,))\n","\n","combined = concatenate([x_1, X_extra, X_extra])\n","x_2 = Dense(8, activation='relu', name='combined-fully-connected-1')(combined)\n","## Output\n","x_2 = Dense(len(components_in_pack), activation='softmax', name='combined-fully-connected-2')(x_2)\n","\n","final_model = Model(inputs=[X_conv, X_extra, X_extra], outputs=x_2)\n","\n","opt = tensorflow.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0, clipvalue=0.6)\n","\n","final_model.compile(optimizer=opt, loss='categorical_crossentropy', \n","                   metrics=['accuracy'])\n","\n","\n","# Generate more data!\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","train_generator = ImageDataGenerator(rotation_range=270)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","time_to_repeat_generator = 5\n","vgg_generator = train_generator.flow([np.repeat(X_train_conv, time_to_repeat_generator, 0), np.repeat(X_train_values, time_to_repeat_generator, 0)], np.repeat(y_train, time_to_repeat_generator, 0), batch_size = 32)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# test_dat, test_label = vgg_generator[0]\n","\n","\n","# # In[227]:\n","\n","\n","# img_nmbr = np.random.randint(len(test_dat[0]))\n","# plt.imshow(test_dat[0][img_nmbr])\n","# plt.title(components_in_pack[np.argmax(test_label[img_nmbr])] + ' | diagonal size: ' + str(test_dat[1][img_nmbr]))\n","# # plt.title(str(test_dat[1][img_nmbr]) + test_label[img_nmbr])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","early_stopping_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n","reduce_lr = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","augmented_history = final_model.fit(vgg_generator,\n","                                    validation_data=([X_test_conv, X_test_values], y_test),\n","                                    epochs = 30,\n","                                    steps_per_epoch = 8, # x * batch_size == amount of data in one epoch\n","                                    verbose = 1,\n","                                    shuffle=True,\n","                                    workers=1,\n","                                    callbacks=[early_stopping_callback, reduce_lr]\n","                                    )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# fig=plt.figure(figsize=(16, 6))\n","\n","# fig.add_subplot(1, 2, 1)\n","# plt.plot(augmented_history.history['accuracy'])\n","# plt.plot(augmented_history.history['val_accuracy'])\n","# plt.title('model accuracy')\n","# plt.ylabel('accuracy')\n","# plt.xlabel('epoch')\n","# plt.legend(['train', 'val'], loc='upper left')\n","\n","# fig.add_subplot(1, 2, 2)\n","# plt.plot(augmented_history.history['loss'])\n","# plt.plot(augmented_history.history['val_loss'])\n","# plt.title('model loss')\n","# plt.ylabel('loss')\n","# plt.xlabel('epoch')\n","# plt.legend(['train', 'val'], loc='upper left')\n","# plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","predictions = final_model.predict([X_test_conv, X_test_values])\n","predictions = predictions.argmax(axis=1)\n","\n","print(f\"Accuracy score {accuracy_score(y_test.argmax(axis=1), predictions) * 100}\")\n","print(classification_report(y_test.argmax(axis=1), predictions))\n","\n","cf = confusion_matrix(y_test.argmax(axis=1), predictions)\n","print(cf)\n","# plt.imshow(cf,cmap='RdYlGn_r')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from uuid import uuid4\n","final_model.save(f\"./models/{pack_name}--{uuid4()}.h5\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","\n","\n"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
